"""
Blueprint Import Router - AI-Powered Blueprint Digitization System

Dual-phase blueprint analysis and vectorization system integrating Claude Sonnet 4
AI for dimensional analysis (Phase 1) with OpenCV computer vision for intelligent
geometry extraction (Phase 2). Converts PDF/image blueprints into CAM-ready vector
files (SVG + DXF R12) for CNC machining workflows.

=================================================================================
MODULE HIERARCHY & CONTEXT LAYERS
=================================================================================

ğŸ“ POSITION IN ARCHITECTURE:
   Luthier's Toolbox/
   â””â”€â”€ services/api/app/routers/
       â”œâ”€â”€ blueprint_router.py        â—„â”€â”€ YOU ARE HERE (Blueprint digitization endpoints)
       â”œâ”€â”€ blueprint_cam_bridge.py    (DXF â†’ CAM toolpath integration)
       â”œâ”€â”€ adaptive_router.py         (Adaptive pocketing engine)
       â””â”€â”€ dxf_plan_router.py         (Direct DXF â†’ toolpath conversion)

ğŸ”§ CORE RESPONSIBILITIES:
   1. Phase 1 AI Analysis - Claude Sonnet 4 dimensional extraction
   2. Phase 2 Geometry Vectorization - OpenCV edge detection + contour extraction
   3. DXF R12/SVG Export - CAM-ready polyline geometry with layer organization
   4. File Upload Handling - Temporary file management with 20MB limit
   5. Service Health Monitoring - Phase 1/2 availability checking

ğŸ”— KEY INTEGRATION POINTS:
   - External Service: services/blueprint-import/ (analyzer, vectorizer, vectorizer_phase2)
   - Claude API: Anthropic's Claude Sonnet 4 for AI dimensional analysis
   - OpenCV Pipeline: Canny edge detection + Hough transforms + contour extraction
   - CAM Bridge: blueprint_cam_bridge.py consumes Phase 2 DXF output
   - Adaptive Engine: Vectorized loops feed into Module L adaptive pocketing

ğŸ“Š DATA FLOW (Blueprint â†’ CAM):
   1. Upload PDF/image â†’ /analyze (Claude extracts scale + dimensions)
   2. AI analysis â†’ /to-svg (Phase 1 annotated SVG with measurements)
   3. Same image â†’ /vectorize-geometry (OpenCV detects edges/contours)
   4. DXF output â†’ blueprint_cam_bridge.py â†’ extract_loops_from_dxf()
   5. LWPOLYLINE loops â†’ adaptive_router.py â†’ toolpath generation
   6. G-code export â†’ CNC machining

=================================================================================
ALGORITHM OVERVIEW
=================================================================================

ğŸ§  PHASE 1: AI-POWERED DIMENSIONAL ANALYSIS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Algorithm: Claude Sonnet 4 Vision API with structured prompts
   
   Steps:
   1. PDF â†’ Image Conversion (using pdf2image for multi-page support)
   2. Base64 encode image for Claude API
   3. Submit to Claude with prompt engineering:
      - "Extract all dimensions with units (inches/mm)"
      - "Detect scale factor (e.g., 1:4, 1/4\"=1')"
      - "Identify blueprint type (guitar, architectural, mechanical)"
      - "Return confidence scores per measurement"
   4. Parse Claude JSON response into structured AnalysisResponse
   5. Return analysis_id (UUID) for tracking and Phase 2 correlation
   
   Output Format:
   {
     "scale": "1:1",
     "dimensions": [
       {"value": 12.75, "unit": "inches", "label": "scale_length", "confidence": 0.95},
       {"value": 16.0, "unit": "inches", "label": "body_width", "confidence": 0.92}
     ],
     "blueprint_type": "guitar",
     "notes": "Detected Les Paul style body..."
   }

ğŸ“ PHASE 2: OPENCV GEOMETRY VECTORIZATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Algorithm: Multi-stage computer vision pipeline
   
   Steps:
   1. Image Preprocessing:
      - Grayscale conversion
      - Gaussian blur (kernel size 5Ã—5)
      - Contrast enhancement (CLAHE)
   
   2. Edge Detection:
      - Canny edge detector (low/high thresholds: 50/150)
      - Morphological closing (fill small gaps)
      - Contour extraction with hierarchy analysis
   
   3. Geometric Feature Detection:
      - Hough Line Transform (detect straight edges)
      - Contour simplification (Douglas-Peucker algorithm)
      - Minimum area filtering (remove noise < 100 pixels)
   
   4. Vectorization:
      - Convert contours to closed polylines
      - Sample splines to linear segments (tolerance 0.5mm)
      - Classify geometry: outer boundaries vs inner islands
   
   5. Dual Export:
      - SVG: Layered output (Contours layer blue, Lines layer red)
      - DXF R12: LWPOLYLINE entities on GEOMETRY layer
   
   Output: svg_path, dxf_path, contours_detected, lines_detected

ğŸ”„ TEMPORARY FILE MANAGEMENT
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Strategy: Per-upload temp directories with UUID tracking
   
   Lifecycle:
   1. Upload arrives â†’ create /tmp/blueprint_<uuid>/
   2. Save to temp file with secure filename
   3. Process with analyzer/vectorizer
   4. Generate outputs in same temp dir
   5. Return file paths (served via /static/<filename>)
   6. Cleanup: Caller responsible for temp dir deletion after download
   
   Safety: All file operations wrapped in try/finally for cleanup

=================================================================================
DATA STRUCTURES & MODELS
=================================================================================

ğŸ“¦ REQUEST/RESPONSE MODELS (Pydantic)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   AnalysisResponse:
     - success: bool
     - filename: str
     - analysis: dict (scale, dimensions, blueprint_type, notes)
     - analysis_id: str (UUID for tracking)
     - message: str
   
   ExportRequest:
     - analysis_data: dict (from /analyze)
     - format: Literal["svg", "dxf"]
     - scale_correction: float (0.1-10.0)
     - width_mm: float, height_mm: float
   
   VectorizeRequest:
     - file: UploadFile
     - analysis_data: str (JSON string, optional)
     - scale_factor: float (0.1-10.0)
   
   VectorizeResponse:
     - success: bool
     - svg_path: str, dxf_path: str
     - contours_detected: int, lines_detected: int
     - processing_time_ms: int
     - message: str

ğŸ“‹ VALIDATION CONSTANTS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   MAX_FILE_SIZE_BYTES = 20 * 1024 * 1024  # 20MB upload limit
   ALLOWED_EXTENSIONS = {'.pdf', '.png', '.jpg', '.jpeg'}
   PHASE2_EXTENSIONS = {'.png', '.jpg', '.jpeg'}  # OpenCV requires raster
   DEFAULT_SVG_WIDTH_MM = 300.0
   DEFAULT_SVG_HEIGHT_MM = 200.0

=================================================================================
API ENDPOINTS REFERENCE
=================================================================================

ğŸ”¹ POST /blueprint/analyze
   Phase 1 AI dimensional analysis with Claude Sonnet 4
   
   Request:
     - file: UploadFile (PDF/PNG/JPG, max 20MB)
   
   Response: AnalysisResponse (scale, dimensions, blueprint_type, analysis_id)
   
   Use Cases:
     - Extract scale factor from blueprint annotations
     - Detect critical dimensions (scale length, body width, etc.)
     - Classify blueprint type for downstream processing
   
   Error Handling:
     - 400: File too large or invalid format
     - 500: Claude API error (check EMERGENT_LLM_KEY env var)

ğŸ”¹ POST /blueprint/to-svg
   Phase 1 SVG export with dimensional annotations
   
   Request: ExportRequest (analysis_data, format="svg", scale_correction, dimensions)
   
   Response: FileResponse (SVG file download)
   
   Use Cases:
     - Generate annotated SVG with measurements overlay
     - Preview blueprint with AI-detected dimensions
     - Print-ready output with scale reference

ğŸ”¹ POST /blueprint/vectorize-geometry
   Phase 2 OpenCV geometry vectorization (primary endpoint)
   
   Request:
     - file: UploadFile (PNG/JPG only)
     - analysis_data: str (optional JSON from /analyze)
     - scale_factor: float (default 1.0)
   
   Response: VectorizeResponse (svg_path, dxf_path, contours_detected, processing_time_ms)
   
   Use Cases:
     - Convert blueprint image to CAM-ready DXF
     - Detect contours and straight edges automatically
     - Export dual format (SVG preview + DXF for CAM)
   
   Output Files:
     - SVG: /tmp/blueprint_phase2_<uuid>/geometry.svg
     - DXF: /tmp/blueprint_phase2_<uuid>/geometry.dxf
   
   Download via: GET /blueprint/static/<filename>

ğŸ”¹ POST /blueprint/to-dxf
   Phase 2 DXF export (PLANNED - use /vectorize-geometry instead)
   
   Status: Placeholder for future direct analysis â†’ DXF workflow
   Current: Returns 501 Not Implemented

ğŸ”¹ GET /blueprint/health
   Service health check and feature detection
   
   Response:
     - status: "healthy" | "degraded"
     - phase: "1" | "2"
     - features: List[str] (available endpoints)
     - coming_soon: List[str] (planned features)
   
   Use Cases:
     - Check if Phase 2 (OpenCV) is installed
     - Detect API key availability for Claude
     - Frontend feature flagging

=================================================================================
USAGE EXAMPLES
=================================================================================

ğŸ“– EXAMPLE 1: Phase 1 - AI Analysis + Annotated SVG
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```python
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

# Step 1: Analyze blueprint with Claude
with open("les_paul_body.pdf", "rb") as f:
    response = client.post(
        "/blueprint/analyze",
        files={"file": ("les_paul_body.pdf", f, "application/pdf")}
    )

result = response.json()
analysis = result["analysis"]
print(f"Scale: {analysis['scale']}")
print(f"Dimensions: {len(analysis['dimensions'])}")

# Step 2: Export annotated SVG
svg_response = client.post(
    "/blueprint/to-svg",
    json={
        "analysis_data": analysis,
        "format": "svg",
        "scale_correction": 1.0,
        "width_mm": 300.0,
        "height_mm": 200.0
    }
)

with open("blueprint_annotated.svg", "wb") as f:
    f.write(svg_response.content)
```

ğŸ“– EXAMPLE 2: Phase 2 - OpenCV Vectorization â†’ DXF/SVG
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```python
import json

# Optional: Use analysis from Phase 1 for scaling
with open("guitar_body.png", "rb") as f:
    response = client.post(
        "/blueprint/vectorize-geometry",
        files={"file": ("guitar_body.png", f, "image/png")},
        data={
            "analysis_data": json.dumps(analysis),  # From Phase 1
            "scale_factor": 1.2
        }
    )

result = response.json()
print(f"DXF Path: {result['dxf_path']}")
print(f"Contours Detected: {result['contours_detected']}")
print(f"Lines Detected: {result['lines_detected']}")

# Download files via GET /blueprint/static/<filename>
dxf_filename = result['dxf_path'].split('/')[-1]
dxf_download = client.get(f"/blueprint/static/{dxf_filename}")
```

ğŸ“– EXAMPLE 3: Full Pipeline â†’ CAM Toolpath
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```python
# Step 1: Vectorize blueprint
with open("body_outline.png", "rb") as f:
    vec_response = client.post(
        "/blueprint/vectorize-geometry",
        files={"file": f},
        data={"scale_factor": 1.0}
    )

dxf_path = vec_response.json()["dxf_path"]

# Step 2: Convert DXF to adaptive pocket toolpath
with open(dxf_path, "rb") as f:
    toolpath_response = client.post(
        "/cam/blueprint/to-adaptive",
        files={"file": f},
        data={
            "tool_d": 6.0,
            "stepover": 0.45,
            "strategy": "Spiral"
        }
    )

moves = toolpath_response.json()["plan"]["moves"]
print(f"Toolpath moves: {len(moves)}")
```

=================================================================================
CRITICAL SAFETY RULES
=================================================================================

ğŸ”’ RULE 1: FILE SIZE ENFORCEMENT
   NEVER accept uploads > 20MB (MAX_FILE_SIZE_BYTES)
   - Check file.size before processing
   - Raise HTTPException(400) with clear message
   - Prevents memory exhaustion and OOM kills

ğŸ”’ RULE 2: EXTENSION VALIDATION
   ONLY accept {'.pdf', '.png', '.jpg', '.jpeg'}
   - Use Path(filename).suffix.lower() for case-insensitive check
   - Phase 2 requires raster formats (no PDF)
   - Reject unknown formats immediately

ğŸ”’ RULE 3: API KEY VALIDATION
   CHECK for EMERGENT_LLM_KEY or ANTHROPIC_API_KEY before Claude calls
   - Return 500 with clear "Missing API key" message
   - Prevents cryptic authentication errors
   - User guidance: Set environment variable before server start

ğŸ”’ RULE 4: TEMPORARY FILE CLEANUP
   ALWAYS use try/finally blocks for temp file operations
   - Create temp dirs with uuid.uuid4() for uniqueness
   - Store cleanup paths in variables
   - Use Path.unlink(missing_ok=True) in finally
   - Prevents disk space exhaustion from orphaned files

ğŸ”’ RULE 5: PHASE 2 GRACEFUL DEGRADATION
   CHECK PHASE2_AVAILABLE flag before OpenCV operations
   - Import vectorizer_phase2 in try/except block
   - Return 501 Not Implemented if Phase 2 unavailable
   - Provide clear installation instructions in error message
   - Allow Phase 1 to work independently

=================================================================================
INTEGRATION POINTS
=================================================================================

ğŸ”— EXTERNAL SERVICE: services/blueprint-import/
   Location: Sibling package at repo root
   Modules:
     - analyzer.py â†’ create_analyzer() (Claude API wrapper)
     - vectorizer.py â†’ create_vectorizer() (Phase 1 SVG generation)
     - vectorizer_phase2.py â†’ create_phase2_vectorizer() (OpenCV pipeline)
   
   Import Pattern:
     BLUEPRINT_SERVICE_PATH = Path(__file__).parent.parent.parent.parent / "blueprint-import"
     sys.path.insert(0, str(BLUEPRINT_SERVICE_PATH))

ğŸ”— CAM BRIDGE ROUTER: blueprint_cam_bridge.py
   Consumes Phase 2 DXF output:
     - extract_loops_from_dxf(dxf_bytes, layer="GEOMETRY")
     - Converts LWPOLYLINE entities to Loop models
     - Feeds loops into adaptive_core_l1.plan_adaptive_l1()
   
   Endpoint: POST /cam/blueprint/to-adaptive

ğŸ”— CLAUDE SONNET 4 API: api.anthropic.com
   Model: claude-sonnet-4-20250514
   Authentication: EMERGENT_LLM_KEY or ANTHROPIC_API_KEY environment variable
   Rate Limits: 50 requests/min (standard tier)
   
   Prompt Engineering:
     - Vision API with base64 image
     - Structured JSON responses
     - Confidence scores per dimension

ğŸ”— OPENCV PIPELINE: vectorizer_phase2.py
   Dependencies:
     - opencv-python==4.12.0
     - scikit-image==0.25.2
     - numpy>=1.24.0
   
   Optional: Check PHASE2_AVAILABLE flag before use

=================================================================================
PERFORMANCE CHARACTERISTICS
=================================================================================

â±ï¸ TIMING BENCHMARKS (Typical Blueprint: 2000Ã—1500px PNG)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Phase 1 Analysis:
     - Claude API call: 2-5 seconds
     - PDF â†’ Image conversion: 0.5-1.5 seconds
     - Total: 3-7 seconds
   
   Phase 2 Vectorization:
     - Edge detection: 0.3-0.8 seconds
     - Contour extraction: 0.2-0.5 seconds
     - DXF export: 0.1-0.3 seconds
     - Total: 1-2 seconds
   
   Combined Pipeline (Phase 1 + Phase 2): 4-9 seconds

ğŸ’¾ MEMORY USAGE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Peak RAM per request:
     - Phase 1 (PDF): ~50-150MB
     - Phase 2 (OpenCV): ~100-300MB
   
   Temp disk usage: 5-30MB per upload

ğŸ”¢ ACCURACY METRICS (Phase 2 Geometry Detection)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   - Contour detection: 85-95% of visible edges
   - False positives: <5% (noise filtering)
   - Dimension tolerance: Â±0.5mm (at 1:1 scale)

=================================================================================
ERROR HANDLING & TROUBLESHOOTING
=================================================================================

âŒ Common Errors:
   1. "File size exceeds 20MB limit"
      â†’ Solution: Compress image or reduce resolution
   
   2. "Missing EMERGENT_LLM_KEY environment variable"
      â†’ Solution: Set API key before server start
         export EMERGENT_LLM_KEY="sk-ant-..."
   
   3. "Phase 2 not available - OpenCV not installed"
      â†’ Solution: Install optional dependencies
         pip install opencv-python==4.12.0 scikit-image==0.25.2
   
   4. "No contours detected in vectorization"
      â†’ Solution: Adjust edge detection thresholds
         Try lower contrast images or increase DPI
   
   5. "DXF has no LWPOLYLINE entities"
      â†’ Solution: Check if vectorization produced valid geometry
         Open DXF in text editor, search for "LWPOLYLINE"

=================================================================================
"""
import logging
import os
import sys
import tempfile
import uuid
from pathlib import Path
from typing import Any, Dict, Optional, Set, Tuple

from fastapi import APIRouter, File, HTTPException, UploadFile
from fastapi.responses import FileResponse

# Schemas extracted to blueprint_schemas.py (Phase 9 decomposition)
from .blueprint_schemas import (
    AnalysisResponse,
    ExportRequest,
    VectorizeRequest,
    VectorizeResponse,
)

# Add blueprint-import service to path
BLUEPRINT_SERVICE_PATH = Path(__file__).parent.parent.parent.parent / "blueprint-import"
sys.path.insert(0, str(BLUEPRINT_SERVICE_PATH))

# Phase 1 AI Analyzer - Optional (graceful degradation if deps missing or no API key)
ANALYZER_AVAILABLE = True
ANALYZER_IMPORT_ERROR: Optional[str] = None

try:
    from analyzer import create_analyzer
except (ImportError, OSError) as e:  # WP-1: narrowed from bare Exception
    ANALYZER_AVAILABLE = False
    ANALYZER_IMPORT_ERROR = f"{type(e).__name__}: {e}"
    create_analyzer = None  # type: ignore

# Phase 1 SVG Vectorizer - Optional (not in Docker image)
try:
    from vectorizer import create_vectorizer
    VECTORIZER_AVAILABLE = True
except ImportError:
    VECTORIZER_AVAILABLE = False
    create_vectorizer = None  # type: ignore

try:
    from vectorizer_phase2 import create_phase2_vectorizer
    PHASE2_AVAILABLE = True
except ImportError:
    PHASE2_AVAILABLE = False

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/blueprint", tags=["blueprint"])

# =============================================================================
# VALIDATION CONSTANTS
# =============================================================================

# Maximum file upload size in bytes (20 MB for blueprint images/PDFs)
MAX_FILE_SIZE_BYTES: int = 20 * 1024 * 1024

# Allowed file extensions for blueprint upload
ALLOWED_EXTENSIONS: Set[str] = {'.pdf', '.png', '.jpg', '.jpeg'}

# Phase 2 image formats (OpenCV compatible)
PHASE2_EXTENSIONS: Set[str] = {'.png', '.jpg', '.jpeg'}

# Default SVG canvas dimensions (mm)
DEFAULT_SVG_WIDTH_MM: float = 300.0
DEFAULT_SVG_HEIGHT_MM: float = 200.0

# Phase 2 edge detection defaults
DEFAULT_EDGE_THRESHOLD_LOW: int = 50
DEFAULT_EDGE_THRESHOLD_HIGH: int = 150
DEFAULT_MIN_CONTOUR_AREA: float = 100.0

# Scale correction bounds (prevent extreme scaling)
MIN_SCALE_FACTOR: float = 0.1
MAX_SCALE_FACTOR: float = 10.0

# Schema classes moved to blueprint_schemas.py (Phase 9 decomposition)
# See: AnalysisResponse, ExportRequest, VectorizeRequest, VectorizeResponse

# =============================================================================
# API ENDPOINTS - PHASE 1 (AI ANALYSIS + ANNOTATED SVG)
# =============================================================================

@router.post("/analyze", response_model=AnalysisResponse)
async def analyze_blueprint(file: UploadFile = File(...)):
    """
    Upload and analyze blueprint PDF or image with Claude Sonnet 4 AI.
    
    Performs dimensional analysis using Anthropic's Claude API to extract:
    - Scale factor (e.g., "1/4 inch = 1 foot")
    - Dimensions with measurements and units
    - Blueprint type classification
    - Confidence scores per detected dimension
    
    Args:
        file: Uploaded blueprint file (PDF, PNG, JPG, JPEG)
    
    Returns:
        AnalysisResponse with:
        - success: bool (True if analysis completed)
        - filename: str (original filename)
        - analysis: dict with keys:
          * scale: str (detected scale, e.g., "1:48")
          * dimensions: List[dict] (measurements with confidence)
          * blueprint_type: str ("architectural", "guitar", "mechanical", "other")
          * notes: str (AI observations)
        - analysis_id: str (UUID for tracking)
        - message: str (summary of results)
    
    File Requirements:
        - Formats: PDF, PNG, JPG, JPEG only
        - Size: Maximum 20MB
        - Resolution: Higher resolution = better detection (300+ DPI recommended)
        - Clarity: Clear dimension lines and text required
    
    Processing Time:
        - PDF (single page): 30-60 seconds
        - Image (PNG/JPG): 20-40 seconds
        - Multi-page PDF: 60-120 seconds
    
    Request Flow:
        1. Validate file extension (PDF, PNG, JPG, JPEG)
        2. Validate file size (<= 20MB)
        3. Read file bytes into memory
        4. Initialize Claude analyzer with API key
        5. Send image to Claude Sonnet 4 for analysis
        6. Parse AI response into structured format
        7. Return analysis with unique ID
    
    Example (Success):
        POST /api/blueprint/analyze
        files: {"file": guitar_body.pdf}
        => {
          "success": true,
          "filename": "guitar_body.pdf",
          "analysis": {
            "scale": "1:1",
            "dimensions": [
              {"value": 12.75, "unit": "inches", "label": "scale_length", "confidence": 0.95},
              {"value": 16.0, "unit": "inches", "label": "body_width", "confidence": 0.92}
            ],
            "blueprint_type": "guitar",
            "notes": "Detected Les Paul style body with 12.75\" scale"
          },
          "analysis_id": "550e8400-e29b-41d4-a716-446655440000",
          "message": "Detected 2 dimensions"
        }
    
    Example (Validation Error):
        POST /api/blueprint/analyze
        files: {"file": document.txt}
        => HTTP 400: "Unsupported file type: .txt. Allowed: {'.pdf', '.png', '.jpg', '.jpeg'}"
    
    Example (File Too Large):
        POST /api/blueprint/analyze
        files: {"file": large_scan.pdf}
        => HTTP 400: "File too large. Maximum size: 20MB"
    
    Example (Analysis Failed):
        POST /api/blueprint/analyze
        files: {"file": blank_page.pdf}
        => {
          "success": false,
          "filename": "blank_page.pdf",
          "analysis": {"error": "No dimensions detected", "notes": "Image appears blank"},
          "message": "Analysis failed"
        }
    
    Notes:
        - Requires EMERGENT_LLM_KEY or ANTHROPIC_API_KEY environment variable
        - Claude API usage billed per request (~$0.02-0.10 per blueprint)
        - Multi-page PDFs: Only first page analyzed currently
        - Low contrast images may produce poor results (preprocess recommended)
        - Handwritten dimensions not supported (typed/printed text only)
    
    Raises:
        HTTPException 400: Invalid file type, file too large, or validation error
        HTTPException 500: Claude API error, network timeout, or analysis crash
    
    Side Effects:
        - Consumes Claude API credits
        - Logs analysis start/completion at INFO level
        - Logs errors at ERROR level
    """
    # --- AI availability gate (H1 optional AI dependency) ---
    api_key = os.environ.get("EMERGENT_LLM_KEY") or os.environ.get("ANTHROPIC_API_KEY")
    if not api_key:
        raise HTTPException(
            status_code=503,
            detail={
                "error": "AI_DISABLED",
                "message": "Blueprint AI is disabled: no API key configured (set EMERGENT_LLM_KEY or ANTHROPIC_API_KEY).",
            },
        )
    if not ANALYZER_AVAILABLE or not create_analyzer:
        raise HTTPException(
            status_code=503,
            detail={
                "error": "AI_DISABLED",
                "message": "Blueprint AI is disabled: analyzer dependencies not installed.",
                "detail": ANALYZER_IMPORT_ERROR,
            },
        )

    try:
        # Validate file type
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in ALLOWED_EXTENSIONS:
            raise HTTPException(
                status_code=400,
                detail=f"Unsupported file type: {file_ext}. Allowed: {ALLOWED_EXTENSIONS}"
            )
        
        # Validate file size (20MB max)
        file_bytes = await file.read()
        if len(file_bytes) > MAX_FILE_SIZE_BYTES:
            raise HTTPException(
                status_code=400,
                detail=f"File too large. Maximum size: {MAX_FILE_SIZE_BYTES / 1024 / 1024:.0f}MB"
            )
        
        # Analyze with Claude
        analyzer = create_analyzer()
        logger.info(f"Starting analysis of {file.filename} ({len(file_bytes)} bytes)")
        analysis_data = await analyzer.analyze_from_bytes(file_bytes, file.filename)
        
        # Check for errors
        if analysis_data.get('error'):
            return AnalysisResponse(
                success=False,
                filename=file.filename,
                analysis=analysis_data,
                message=analysis_data.get('notes', 'Analysis failed')
            )
        
        dimensions_count = len(analysis_data.get('dimensions', []))
        logger.info(f"Analysis complete: {dimensions_count} dimensions detected")
        
        return AnalysisResponse(
            success=True,
            filename=file.filename,
            analysis=analysis_data,
            message=f"Detected {dimensions_count} dimensions"
        )
    
    except ValueError as e:
        # ValueError from analyzer = missing API key or config issue â†’ 503
        logger.error(f"AI configuration error: {e}")
        raise HTTPException(
            status_code=503,
            detail={"error": "AI_DISABLED", "message": str(e)},
        )
    except HTTPException:  # WP-1: pass through HTTPException
        raise
    except Exception as e:  # WP-1: governance catch-all â€” HTTP endpoint
        logger.error(f"Error analyzing blueprint: {e}")
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")

@router.post("/to-svg")
async def export_to_svg(request: ExportRequest) -> FileResponse:
    """
    Convert AI analysis to SVG file with dimension annotations.
    
    Phase 1 implementation: Generates SVG visualization of detected dimensions
    with annotation lines and measurement labels. Does NOT include full geometry
    (use Phase 2 /vectorize-geometry for edge-detected geometry).
    
    Args:
        request: ExportRequest containing:
            - analysis_data: dict from /analyze endpoint
            - scale_correction: float (0.1-10.0) for manual scaling adjustment
            - width_mm: float (canvas width in millimeters)
            - height_mm: float (canvas height in millimeters)
    
    Returns:
        FileResponse with SVG file download
        Headers include:
        - Content-Disposition: attachment with filename
        - X-Scale-Factor: Applied scale correction value
    
    SVG Structure:
        - Canvas sized to width_mm Ã— height_mm
        - Dimension lines drawn as <line> elements
        - Measurement labels as <text> elements
        - Optional grid overlay for reference
        - Preserves aspect ratio from analysis
    
    Request Flow:
        1. Validate format (must be "svg" for Phase 1)
        2. Validate scale_correction bounds (0.1-10.0)
        3. Create temporary SVG file in system temp directory
        4. Initialize Phase 1 vectorizer with units="mm"
        5. Generate SVG from analysis dimensions
        6. Return file with download headers
    
    Example:
        POST /api/blueprint/to-svg
        {
          "analysis_data": {
            "dimensions": [
              {"value": 12.75, "unit": "inches", "label": "scale_length"},
              {"value": 16.0, "unit": "inches", "label": "body_width"}
            ],
            "scale": "1:1"
          },
          "scale_correction": 1.0,
          "width_mm": 400.0,
          "height_mm": 300.0
        }
        => SVG file: blueprint_<uuid>.svg
    
    Notes:
        - Phase 1: Annotation-only (dimension lines + labels)
        - Phase 2: Use /vectorize-geometry for full edge-detected geometry
        - DXF export planned for Phase 2 (not available in /to-svg)
        - Temporary files stored in system temp directory
        - Files not auto-deleted (client responsible for cleanup)
    
    Raises:
        HTTPException 400: Invalid format (not "svg") or invalid scale_correction
        HTTPException 500: SVG generation error or file I/O failure
    
    Side Effects:
        - Creates temporary SVG file in system temp directory
        - Logs SVG generation at INFO level
        - Logs errors at ERROR level
    """
    try:
        if request.format != "svg":
            raise HTTPException(
                status_code=400,
                detail="Only SVG format supported in Phase 1. DXF coming in Phase 2."
            )
        
        # Check if vectorizer is available (not in Docker)
        if not VECTORIZER_AVAILABLE:
            raise HTTPException(
                status_code=501,
                detail="Blueprint vectorizer not available in this deployment. Use local development environment."
            )
        
        # Validate scale correction bounds
        if not (MIN_SCALE_FACTOR <= request.scale_correction <= MAX_SCALE_FACTOR):
            raise HTTPException(
                status_code=400,
                detail=f"scale_correction must be between {MIN_SCALE_FACTOR} and {MAX_SCALE_FACTOR}"
            )
        
        # Create temporary SVG file
        temp_dir = tempfile.gettempdir()
        svg_filename = f"blueprint_{uuid.uuid4().hex[:8]}.svg"
        svg_path = os.path.join(temp_dir, svg_filename)
        
        # Generate SVG
        vectorizer = create_vectorizer(units="mm")
        vectorizer.dimensions_to_svg(
            request.analysis_data,
            svg_path,
            width_mm=request.width_mm,
            height_mm=request.height_mm
        )
        
        logger.info(f"Generated SVG: {svg_path}")
        
        return FileResponse(
            svg_path,
            media_type="image/svg+xml",
            filename=svg_filename,
            headers={
                "Content-Disposition": f"attachment; filename={svg_filename}",
                "X-Scale-Factor": str(request.scale_correction)
            }
        )
    except HTTPException:  # WP-1: pass through HTTPException
        raise
    except Exception as e:  # WP-1: governance catch-all â€” HTTP endpoint
        logger.error(f"Error exporting SVG: {e}")
        raise HTTPException(status_code=500, detail=f"SVG export failed: {str(e)}")

# =============================================================================
# API ENDPOINTS - PHASE 2 (OPENCV VECTORIZATION + DXF/SVG EXPORT)
# =============================================================================

@router.post("/to-dxf")
async def export_to_dxf(request: ExportRequest) -> FileResponse:
    """
    Convert AI analysis to DXF R12 file with intelligent geometry detection.
    
    **STATUS: PLANNED - Phase 2 implementation in progress**
    
    Phase 2 Features (when available):
        - OpenCV edge detection + Canny operator
        - Hough line and circle detection
        - Contour extraction and simplification
        - DXF R12 export with closed polylines
        - Layered output: GEOMETRY, LINES, DIMENSIONS
        - CAM-ready for Fusion 360, VCarve, Mach4
    
    Args:
        request: ExportRequest containing:
            - analysis_data: dict from /analyze endpoint
            - format: str (must be "dxf")
            - scale_correction: float (0.1-10.0)
            - width_mm: float (canvas width)
            - height_mm: float (canvas height)
    
    Returns:
        FileResponse with DXF R12 file (when implemented)
    
    Current Status:
        - Phase 2 vectorizer module available: Check PHASE2_AVAILABLE flag
        - Use /vectorize-geometry endpoint for current DXF export functionality
        - This endpoint will replace /vectorize-geometry in future release
    
    Migration Path:
        1. Current: Use POST /vectorize-geometry with file upload
        2. Future: Use POST /to-dxf with analysis_data only
    
    Example (Future):
        POST /api/blueprint/to-dxf
        {
          "analysis_data": {...from /analyze...},
          "format": "dxf",
          "scale_correction": 1.0,
          "width_mm": 300.0,
          "height_mm": 200.0
        }
        => DXF R12 file: blueprint_<uuid>.dxf
    
    Notes:
        - Requires Phase 2 vectorizer (opencv-python + ezdxf)
        - DXF format will be R12 (AC1009) for maximum CAM compatibility
        - Layers: GEOMETRY (closed polylines), LINES (open segments), DIMENSIONS (text)
    
    Raises:
        HTTPException 501: Not implemented (use /vectorize-geometry instead)
    """
    if not PHASE2_AVAILABLE:
        raise HTTPException(
            status_code=501,
            detail="Phase 2 vectorizer not available. Install opencv-python and ezdxf."
        )
    
    raise HTTPException(
        status_code=501,
        detail="DXF export endpoint under development. Use /vectorize-geometry for now."
    )

@router.post("/vectorize-geometry", response_model=VectorizeResponse)
async def vectorize_geometry(
    file: UploadFile = File(...),
    analysis_data: str = "",  # JSON string from /analyze
    scale_factor: float = 1.0
):
    """
    Phase 2: Intelligent geometry detection from blueprint image using OpenCV.
    
    Combines AI dimensional analysis with edge detection to produce CAM-ready
    vector files (SVG + DXF R12). Uses Canny edge detection, Hough transforms,
    and contour extraction for precise geometry.
    
    Args:
        file: Blueprint image file (PNG, JPG, JPEG - same as used for /analyze)
        analysis_data: JSON string from /analyze endpoint (optional but recommended)
        scale_factor: Scaling multiplier for output coordinates (0.1-10.0)
    
    Returns:
        VectorizeResponse with:
        - success: bool (True if vectorization completed)
        - svg_path: str (path to generated SVG file)
        - dxf_path: str (path to generated DXF R12 file)
        - contours_detected: int (number of closed contours found)
        - lines_detected: int (number of line segments detected)
        - processing_time_ms: int (total processing time)
        - message: str (summary of detection results)
    
    Processing Pipeline:
        1. Upload validation (format and size checks)
        2. Save uploaded image to temporary file
        3. Canny edge detection (default thresholds: 50, 150)
        4. Hough line transform for straight edges
        5. Hough circle transform for curved features
        6. Contour extraction and simplification
        7. Scale application from analysis_data
        8. SVG generation with layers
        9. DXF R12 generation with closed polylines
        10. Return file paths and statistics
    
    OpenCV Parameters (defaults):
        - edge_threshold_low: 50 (Canny low threshold)
        - edge_threshold_high: 150 (Canny high threshold)
        - min_contour_area: 100.0 pixelsÂ² (filter small noise)
        - Gaussian blur: 5Ã—5 kernel (pre-processing)
        - Contour approximation: Douglas-Peucker epsilon=0.01
    
    Request Flow:
        1. Validate file extension (PNG, JPG, JPEG only for Phase 2)
        2. Parse analysis_data JSON if provided
        3. Read uploaded file bytes
        4. Save to temporary file with original extension
        5. Create output directory in system temp
        6. Initialize Phase 2 vectorizer (OpenCV-based)
        7. Run analyze_and_vectorize() pipeline
        8. Calculate processing time
        9. Return paths and statistics
        10. Clean up temp input file (output files preserved)
    
    Example (with analysis):
        POST /api/blueprint/vectorize-geometry
        Content-Type: multipart/form-data
        
        file: body_plan.png
        analysis_data: '{"dimensions":[{"value":12.75,"unit":"inches"}],"scale":"1:1"}'
        scale_factor: 1.0
        
        => {
          "success": true,
          "svg_path": "/tmp/blueprint_phase2_xyz/output.svg",
          "dxf_path": "/tmp/blueprint_phase2_xyz/output.dxf",
          "contours_detected": 15,
          "lines_detected": 42,
          "processing_time_ms": 3500,
          "message": "Detected 15 contours and 42 line segments"
        }
    
    Example (without analysis):
        POST /api/blueprint/vectorize-geometry
        Content-Type: multipart/form-data
        
        file: body_plan.png
        scale_factor: 1.2
        
        => {
          "success": true,
          "svg_path": "/tmp/blueprint_phase2_xyz/output.svg",
          "dxf_path": "/tmp/blueprint_phase2_xyz/output.dxf",
          "contours_detected": 18,
          "lines_detected": 50,
          "processing_time_ms": 3200,
          "message": "Detected 18 contours and 50 line segments"
        }
    
    Output Files:
        - SVG: Layered vector graphics with stroke styling
          * Layer 1: Detected geometry (black, 0.5pt stroke)
          * Layer 2: Dimension annotations (red, 0.25pt stroke)
          * Layer 3: Grid overlay (gray, dashed)
        
        - DXF R12: CAM-ready format
          * Layer GEOMETRY: Closed polylines (for pocketing/profiling)
          * Layer LINES: Open line segments (for engraving)
          * Layer DIMENSIONS: Text labels with measurements
    
    Notes:
        - Requires Phase 2 vectorizer (check PHASE2_AVAILABLE before calling)
        - Install dependencies: pip install opencv-python scikit-image ezdxf
        - Image quality affects detection: 300+ DPI recommended
        - High contrast images produce better results
        - Processing time scales with image resolution and complexity
        - Temporary input files cleaned up in finally block
        - Output files NOT auto-deleted (client responsible for cleanup)
    
    Raises:
        HTTPException 400: Invalid file type, JSON parse error, or validation failure
        HTTPException 500: OpenCV error, vectorization crash, or file I/O failure
        HTTPException 501: Phase 2 not available (missing opencv-python or scikit-image)
    
    Side Effects:
        - Creates temporary input file (cleaned up in finally)
        - Creates temporary output directory with SVG and DXF files (NOT cleaned up)
        - Logs processing start/completion at INFO level
        - Logs errors at ERROR level
        - Consumes CPU for image processing (3-10 seconds typical)
    """
    if not PHASE2_AVAILABLE:
        raise HTTPException(
            status_code=501,
            detail="Phase 2 not available. Install: pip install opencv-python scikit-image"
        )
    
    import json
    import time
    start_time = time.time()
    
    try:
        # Parse analysis data
        try:
            analysis_dict = json.loads(analysis_data) if analysis_data else {}
        except json.JSONDecodeError:
            raise HTTPException(
                status_code=400,
                detail="Invalid analysis_data JSON"
            )
        
        # Validate file
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in PHASE2_EXTENSIONS:
            raise HTTPException(
                status_code=400,
                detail=f"Unsupported file type: {file_ext}. Phase 2 requires PNG/JPG"
            )
        
        # Validate scale factor
        if not (MIN_SCALE_FACTOR <= scale_factor <= MAX_SCALE_FACTOR):
            raise HTTPException(
                status_code=400,
                detail=f"scale_factor must be between {MIN_SCALE_FACTOR} and {MAX_SCALE_FACTOR}"
            )
        
        # Save uploaded image to temp file
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp:
            file_bytes = await file.read()
            tmp.write(file_bytes)
            tmp_path = tmp.name
        
        logger.info(f"Starting Phase 2 vectorization: {file.filename} ({len(file_bytes)} bytes)")
        
        # Create output directory
        output_dir = tempfile.mkdtemp(prefix="blueprint_phase2_")
        
        # Run Phase 2 vectorization
        vectorizer = create_phase2_vectorizer()
        result = vectorizer.analyze_and_vectorize(
            image_path=tmp_path,
            analysis_data=analysis_dict,
            output_dir=output_dir,
            scale_factor=scale_factor
        )
        
        # Calculate processing time
        processing_time = int((time.time() - start_time) * 1000)
        
        logger.info(f"Phase 2 complete: {result['contours']} contours, {result['lines']} lines in {processing_time}ms")
        
        return VectorizeResponse(
            success=True,
            svg_path=result['svg'],
            dxf_path=result['dxf'],
            contours_detected=result['contours'],
            lines_detected=result['lines'],
            processing_time_ms=processing_time,
            message=f"Detected {result['contours']} contours and {result['lines']} line segments"
        )
    except HTTPException:  # WP-1: pass through HTTPException
        raise
    except Exception as e:  # WP-1: governance catch-all â€” HTTP endpoint
        logger.error(f"Phase 2 vectorization failed: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Geometry detection failed: {str(e)}"
        )
    finally:
        # Clean up temp file
        try:
            if 'tmp_path' in locals():
                Path(tmp_path).unlink(missing_ok=True)
        except OSError as e:  # WP-1: narrowed from bare Exception
            logger.warning(f"Failed to clean up temp file: {e}")

# =============================================================================
# API ENDPOINTS - SERVICE HEALTH & DIAGNOSTICS
# =============================================================================

