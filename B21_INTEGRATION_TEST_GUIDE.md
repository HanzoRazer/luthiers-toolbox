# B21 Multi-Run Comparison - Integration Test Guide

**Status:** Ready for Testing  
**Route:** `/lab/compare-runs`  
**Date:** November 28, 2025

---

## âœ… Pre-Test Checklist

- [x] Backend API running (`uvicorn app.main:app --reload --port 8000`)
- [x] Frontend dev server running (`npm run dev` in `client/`)
- [x] Chart.js installed (`chart.js@^4.4.0` in package.json)
- [x] Route registered (geometry store CAM targets)
- [x] Component created (`packages/client/src/views/MultiRunComparisonView.vue`)

---

## ğŸ§ª Manual Integration Tests

### **Test 1: Route Navigation**

**Steps:**
1. Open browser to `http://localhost:5173`
2. Navigate to `/lab/compare-runs` in address bar
3. Press Enter

**Expected Results:**
- âœ… MultiRunComparisonView component loads without 404
- âœ… Page title shows "Multi-Run Comparison"
- âœ… Preset selector section visible
- âœ… No console errors in DevTools

**Actual Results:**
```
[ ] Pass
[ ] Fail - Error: ___________________________
```

---

### **Test 2: Preset Selector Loading**

**Prerequisites:** 
- Create 2-3 presets with job lineage using B19 "Clone as Preset" feature
- OR run `.\test_multi_run_comparison.ps1` to create test presets

**Steps:**
1. On `/lab/compare-runs`, observe preset selector section
2. Check that only presets with `job_source_id` appear
3. Verify empty state message if no lineage presets exist

**Expected Results:**
- âœ… Preset selector displays grid of checkboxes
- âœ… Only presets with job lineage shown (not all presets)
- âœ… Each preset shows: name, kind badge, truncated job ID
- âœ… Empty state: "Clone jobs as presets using B19 feature" if none

**Actual Results:**
```
[ ] Pass
[ ] Fail - Error: ___________________________
```

---

### **Test 3: Multi-Select Functionality**

**Steps:**
1. Select 1 preset by clicking checkbox
2. Verify "Compare Runs" button disabled
3. Select 2nd preset
4. Verify "Compare Runs" button enabled
5. Verify selection counter shows "2 selected"
6. Click "Clear selection"
7. Verify all checkboxes unchecked

**Expected Results:**
- âœ… Single selection â†’ Button disabled with tooltip/message
- âœ… 2+ selections â†’ Button enabled (green)
- âœ… Counter updates dynamically: "X presets selected"
- âœ… Clear button resets all checkboxes
- âœ… Selected presets have blue background

**Actual Results:**
```
[ ] Pass
[ ] Fail - Error: ___________________________
```

---

### **Test 4: Run Comparison**

**Steps:**
1. Select 3 presets with different sim_time_s values
2. Click "Compare Runs" button
3. Wait for API call to complete
4. Observe results display

**Expected Results:**
- âœ… Loading spinner appears during API call
- âœ… No error messages
- âœ… Summary stats cards display (4 cards):
   - Runs Compared: 3
   - Avg Time: [value]s
   - Avg Energy: [value]J
   - Avg Moves: [value]
- âœ… Trend badges show (if applicable):
   - Time trend: Green (improving) / Red (degrading) / Gray (stable)
   - Energy trend: similar color coding
- âœ… Recommendations panel displays with bullet points
- âœ… Comparison table shows all 3 runs (8 columns)
- âœ… Best run highlighted green with ğŸ† trophy
- âœ… Worst run highlighted red with âš ï¸ warning

**Actual Results:**
```
[ ] Pass
[ ] Fail - Error: ___________________________
```

---

### **Test 5: Chart.js Bar Chart**

**Steps:**
1. After comparison completes, scroll to chart section
2. Verify bar chart renders
3. Hover over bars to see tooltips
4. Check bar colors

**Expected Results:**
- âœ… Bar chart displays with Y-axis "Time (seconds)"
- âœ… 3 bars (one per preset)
- âœ… Bar colors:
   - Best run: Green
   - Worst run: Red
   - Others: Blue
- âœ… Tooltip shows time value on hover (e.g., "95.80s")
- âœ… Chart responsive (scales with window resize)

**Actual Results:**
```
[ ] Pass
[ ] Fail - Error: ___________________________
```

---

### **Test 6: Efficiency Score Progress Bars**

**Steps:**
1. In comparison table, check "Efficiency" column
2. Verify progress bars display
3. Check color coding

**Expected Results:**
- âœ… Each row has progress bar (0-100)
- âœ… Color by score:
   - Green: â‰¥70
   - Yellow: 40-69
   - Red: <40
- âœ… Score text displays next to bar (e.g., "85/100")

**Actual Results:**
```
[ ] Pass
[ ] Fail - Error: ___________________________
```

---

### **Test 7: CSV Export**

**Steps:**
1. After comparison, click "ğŸ“¥ Export as CSV" button
2. Wait for file download
3. Open CSV file in Excel/text editor

**Expected Results:**
- âœ… CSV file downloads with timestamp name
- âœ… Headers: Preset Name, Time (s), Energy (J), Moves, Issues, Strategy, Feed XY, Efficiency Score
- âœ… 3 data rows (one per preset)
- âœ… Values match table display
- âœ… Numeric formatting correct (2 decimals for time, 0 for energy)

**Actual Results:**
```
[ ] Pass
[ ] Fail - Error: ___________________________
```

---

### **Test 8: State Persistence (localStorage)**

**Steps:**
1. Select 2 presets
2. Run comparison
3. Open DevTools â†’ Application â†’ Local Storage
4. Verify keys exist:
   - `multirun.selectedPresets`
   - `multirun.lastComparison`
   - `multirun.lastUpdated`
5. Refresh page (F5)
6. Verify state restored

**Expected Results:**
- âœ… localStorage keys populated after comparison
- âœ… `selectedPresets` is JSON array of IDs
- âœ… `lastComparison` contains full result object
- âœ… `lastUpdated` is Unix timestamp (ms)
- âœ… After reload: checkboxes re-checked
- âœ… After reload: comparison table/chart restored
- âœ… After reload: no API call made (cached)

**Actual Results:**
```
[ ] Pass
[ ] Fail - Error: ___________________________
```

---

### **Test 9: New Comparison Reset**

**Steps:**
1. After comparison, click "ğŸ”„ New Comparison" button
2. Observe state reset
3. Check localStorage in DevTools

**Expected Results:**
- âœ… Comparison results cleared (table/chart hidden)
- âœ… All checkboxes unchecked
- âœ… "Compare Runs" button disabled
- âœ… localStorage keys removed (all 3)
- âœ… No error messages

**Actual Results:**
```
[ ] Pass
[ ] Fail - Error: ___________________________
```

---

### **Test 10: Error Handling**

**Steps:**
1. Select only 1 preset
2. Click "Compare Runs" button
3. Observe error handling

**Expected Results:**
- âœ… Button disabled (can't click)
- âœ… OR: Error message displays: "Please select at least 2 presets"
- âœ… No crash or console errors

**Actual Results:**
```
[ ] Pass
[ ] Fail - Error: ___________________________
```

---

### **Test 11: Backend API Integration**

**Steps:**
1. Open Network tab in DevTools
2. Run comparison
3. Inspect API call

**Expected Results:**
- âœ… POST request to `/api/presets/compare-runs`
- âœ… Request body contains:
   - `preset_ids`: array of 2+ IDs
   - `include_trends`: true
   - `include_recommendations`: true
- âœ… Response status: 200 OK
- âœ… Response contains:
   - `runs[]` array
   - `avg_time_s`, `min_time_s`, `max_time_s`
   - `time_trend`, `energy_trend`
   - `best_run_id`, `worst_run_id`
   - `recommendations[]` array

**Actual Results:**
```
[ ] Pass
[ ] Fail - Error: ___________________________
```

---

### **Test 12: Navigation Integration**

**Steps:**
1. Navigate to a different page (e.g., Preset Hub)
2. Use geometry store to navigate: `sendToCAM('compare-runs')`
3. Or: Look for navigation link in sidebar/toolbar
4. Click link

**Expected Results:**
- âœ… Navigation link visible with ğŸ“Š icon
- âœ… Link labeled "Multi-Run Comparison"
- âœ… Clicking link routes to `/lab/compare-runs`
- âœ… Component loads correctly

**Actual Results:**
```
[ ] Pass
[ ] Fail - Error: ___________________________
```

---

## ğŸ› Known Issues / Limitations

- [ ] No cross-tab localStorage sync (requires storage event listener)
- [ ] Comparison cache TTL fixed at 24h (not configurable)
- [ ] No energy trend chart (only time chart implemented)
- [ ] No parameter sensitivity analysis
- [ ] No PDF export (CSV only)
- [ ] Best/worst highlighting requires at least 2 runs

---

## ğŸ“Š Test Results Summary

**Date Tested:** _________________  
**Tester:** _____________________  
**Environment:** _________________

| Test | Status | Notes |
|------|--------|-------|
| 1. Route Navigation | â¬œ Pass / â¬œ Fail | |
| 2. Preset Selector | â¬œ Pass / â¬œ Fail | |
| 3. Multi-Select | â¬œ Pass / â¬œ Fail | |
| 4. Run Comparison | â¬œ Pass / â¬œ Fail | |
| 5. Chart.js Chart | â¬œ Pass / â¬œ Fail | |
| 6. Efficiency Bars | â¬œ Pass / â¬œ Fail | |
| 7. CSV Export | â¬œ Pass / â¬œ Fail | |
| 8. State Persistence | â¬œ Pass / â¬œ Fail | |
| 9. New Comparison | â¬œ Pass / â¬œ Fail | |
| 10. Error Handling | â¬œ Pass / â¬œ Fail | |
| 11. API Integration | â¬œ Pass / â¬œ Fail | |
| 12. Navigation | â¬œ Pass / â¬œ Fail | |

**Overall Status:** â¬œ All Pass / â¬œ Some Failures  
**Ready for Production:** â¬œ Yes / â¬œ No (see issues)

---

## ğŸš€ Next Steps After Testing

If all tests pass:
1. âœ… Mark B21 as 100% complete in status tracker
2. âœ… Update UNIFIED_PRESET_INTEGRATION_STATUS.md
3. âœ… Create production deployment plan
4. âœ… Consider Option F (Extension Validation) or other enhancements

If tests fail:
1. Document issues in "Known Issues" section above
2. Create GitHub issues for each failure
3. Prioritize fixes by severity
4. Re-test after fixes

---

## ğŸ“š Documentation References

- [B21_MULTI_RUN_COMPARISON_COMPLETE.md](./B21_MULTI_RUN_COMPARISON_COMPLETE.md) â€“ Full feature documentation
- [B21_MULTI_RUN_COMPARISON_QUICKREF.md](./B21_MULTI_RUN_COMPARISON_QUICKREF.md) â€“ Quick reference
- [B21_ROUTE_REGISTRATION_GUIDE.md](./B21_ROUTE_REGISTRATION_GUIDE.md) â€“ Route setup guide
- [STATE_PERSISTENCE_QUICKREF.md](./STATE_PERSISTENCE_QUICKREF.md) â€“ localStorage implementation
- [test_multi_run_comparison.ps1](./test_multi_run_comparison.ps1) â€“ Backend API tests

---

**Test Guide Version:** 1.0  
**Last Updated:** November 28, 2025
