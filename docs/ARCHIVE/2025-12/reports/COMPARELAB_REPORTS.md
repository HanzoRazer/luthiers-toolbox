# CompareLab Reports

This document describes how to generate exportable **HTML diff reports**
using the CompareLab automation API.

**Status:** ‚úÖ B22.14 Complete  
**Date:** December 3, 2025

---

## 1. Prerequisites

- **CompareLab server running** (FastAPI app with `/compare/run` from B22.13)
- **Python 3.10+** available
- **httpx installed**: `pip install httpx`
- The following tools present in the repo:
  - `tools/compare_report_lib.py`
  - `tools/compare_report_cli.py`

---

## 2. CLI Usage

From the repo root, with the server running on `http://localhost:8000`:

```bash
python tools/compare_report_cli.py \
  --left path/to/left.svg \
  --right path/to/right.svg \
  --mode overlay \
  --out reports/left_vs_right.html
```

### Arguments

| Argument | Required | Default | Description |
|----------|----------|---------|-------------|
| `--base-url` | No | `http://localhost:8000` | CompareLab API base URL |
| `--left` | **Yes** | - | Path to the "left" SVG file |
| `--right` | **Yes** | - | Path to the "right" SVG file |
| `--mode` | No | `overlay` | Compare mode: `side-by-side`, `overlay`, or `delta` |
| `--out` | No | `compare-report.html` | Output HTML file path |

### How It Works

The CLI performs these steps:

1. **Reads SVG files** from `--left` and `--right` paths
2. **Calls automation API**: `POST /compare/run` with `export=["json","png"]`
3. **Builds HTML report** using `build_compare_report_html()` from `compare_report_lib.py`
4. **Writes result** to `--out` file

### Example Output

```
üìÑ Reading SVG files...
   Left:  examples/comparelab/body_v1.svg
   Right: examples/comparelab/body_v2.svg
üîÑ Calling CompareLab API: http://localhost:8000/compare/run
   Mode: overlay
‚úì Compare completed successfully
  PNG preview: 45328 bytes
üìù Building HTML report...
üíæ Writing report to: reports/body_v1_vs_v2.html
‚úÖ CompareLab report saved to: reports/body_v1_vs_v2.html
   Open in browser: file:///Users/you/luthiers-toolbox/reports/body_v1_vs_v2.html
```

---

## 3. Report Contents

Each generated HTML report includes:

### Header Section
- **Title**: "CompareLab Report"
- **File names**: Left and right SVG filenames
- **Mode badge**: Active compare mode (overlay/delta/etc)
- **Generation timestamp**: ISO format
- **Diff status**: "Differences detected" or "No differences detected"

### Summary Cards (3-column grid)
1. **Full BBox**: Complete bounding box of the geometry
2. **Diff BBox**: Bounding box of the diff region (or "‚Äì" if none)
3. **Layer entries**: Count of layers in the compare result

### Visual Preview
- **Embedded PNG**: Base64-encoded PNG image of the comparison
- **Fallback**: "No PNG preview included" message if `png_data_base64` not provided

### Bounding Boxes Detail
- **Full bounding box**: Complete geometry bounds as JSON
- **Diff region**: Diff-specific bounds as JSON (or "‚Äì")

### Layers Table
| Layer | L | R |
|-------|---|---|
| Body | ‚úì | ‚úì |
| Inlay | ‚úì | ‚Äì |
| Registration | ‚Äì | ‚úì |

- **L**: Present in left SVG
- **R**: Present in right SVG
- **Checkmark (‚úì)**: Layer present
- **Dash (‚Äì)**: Layer not present

### Footer
- Generated by attribution
- Snapshot disclaimer

---

## 4. API Contract

### Request Format

`tools/compare_report_cli.py` sends this payload to `/compare/run`:

```json
{
  "left": {
    "kind": "svg",
    "value": "<svg>...</svg>"
  },
  "right": {
    "kind": "svg",
    "value": "<svg>...</svg>"
  },
  "mode": "overlay",
  "export": ["json", "png"],
  "zoom_to_diff": true,
  "include_layers": true
}
```

### Expected Response

```json
{
  "mode": "overlay",
  "json": {
    "fullBBox": {
      "minX": 0,
      "minY": 0,
      "maxX": 100,
      "maxY": 100
    },
    "diffBBox": {
      "minX": 10,
      "minY": 20,
      "maxX": 90,
      "maxY": 80
    },
    "layers": [
      {
        "id": "inlay",
        "label": "Inlay",
        "inLeft": true,
        "inRight": true
      },
      {
        "id": "registration",
        "label": "Registration",
        "inLeft": true,
        "inRight": false
      }
    ]
  },
  "png_data_base64": "iVBORw0KGgoAAAANSUhEUgAA..."
}
```

### Minimal Requirements

The report builder gracefully handles missing fields:

- **Required**:
  - `mode` (string)
  - `json.fullBBox` (object)
  
- **Optional**:
  - `json.diffBBox` (object or null) - Shows "‚Äì" if null
  - `json.layers` (array) - Shows "No layer metadata" if missing
  - `png_data_base64` (string) - Shows text note if missing

---

## 5. Report Styling

### Design Principles
- **Dark theme**: Optimized for developer workflow
- **Responsive**: Works on mobile, tablet, desktop
- **Self-contained**: No external CSS or JS dependencies
- **Print-friendly**: Clean layout for PDF conversion

### Color Scheme
- **Background**: Dark gradient (`#05070b` to `#020617`)
- **Card background**: Dark blue (`#101827`)
- **Accent**: Blue (`#3b82f6`)
- **Text**: Light gray (`#e5e7eb`)
- **Muted text**: Medium gray (`#9ca3af`)

### Key Features
- **Mode badge**: Pill-shaped indicator with accent color
- **Summary cards**: Gradient backgrounds with rounded corners
- **Code blocks**: Monospace font with dark background
- **Responsive grid**: Auto-fits columns based on screen width
- **Image container**: Bordered, rounded preview area

---

## 6. Golden Example (Recommended)

### Setup Test Assets

Create example SVG pairs in the repo:

```bash
mkdir -p examples/comparelab
```

Add test files:
- `examples/comparelab/basic_left.svg` - Simple guitar body outline
- `examples/comparelab/basic_right.svg` - Same body with minor changes

### Generate Golden Report

```bash
python tools/compare_report_cli.py \
  --left examples/comparelab/basic_left.svg \
  --right examples/comparelab/basic_right.svg \
  --out reports/golden_basic_compare.html
```

### Automated Test (Optional)

Create `tests/test_compare_reports.py`:

```python
import subprocess
import os

def test_report_generation():
    """Test that CLI generates valid HTML report."""
    result = subprocess.run([
        "python", "tools/compare_report_cli.py",
        "--left", "examples/comparelab/basic_left.svg",
        "--right", "examples/comparelab/basic_right.svg",
        "--out", "reports/test_report.html"
    ], capture_output=True, text=True)
    
    assert result.returncode == 0
    assert os.path.exists("reports/test_report.html")
    
    with open("reports/test_report.html", "r") as f:
        html = f.read()
        assert "CompareLab Report" in html
        assert "basic_left.svg" in html
        assert "basic_right.svg" in html
```

Run with: `pytest tests/test_compare_reports.py`

---

## 7. Programmatic Usage

### Python Script Example

```python
import asyncio
from compare_report_lib import CompareReportContext, build_compare_report_html
import httpx

async def generate_report(left_svg: str, right_svg: str, out_path: str):
    """Generate report from SVG strings."""
    
    # Call API
    async with httpx.AsyncClient(base_url="http://localhost:8000") as client:
        resp = await client.post("/compare/run", json={
            "left": {"kind": "svg", "value": left_svg},
            "right": {"kind": "svg", "value": right_svg},
            "mode": "overlay",
            "export": ["json", "png"],
        })
        data = resp.json()
    
    # Build report
    ctx = CompareReportContext(
        left_name="design_a.svg",
        right_name="design_b.svg",
        mode=data["mode"],
        json_payload=data["json"],
        png_data_base64=data.get("png_data_base64"),
    )
    
    html = build_compare_report_html(ctx)
    
    # Save
    with open(out_path, "w") as f:
        f.write(html)

# Usage
asyncio.run(generate_report(svg_left, svg_right, "report.html"))
```

### Direct HTTP Example (curl)

```bash
# Call API and save JSON
curl -X POST http://localhost:8000/compare/run \
  -H "Content-Type: application/json" \
  -d '{
    "left": {"kind": "svg", "value": "<svg>...</svg>"},
    "right": {"kind": "svg", "value": "<svg>...</svg>"},
    "mode": "overlay",
    "export": ["json", "png"]
  }' \
  -o compare_result.json

# Then process with Python
python -c "
import json
from tools.compare_report_lib import CompareReportContext, build_compare_report_html

with open('compare_result.json') as f:
    data = json.load(f)

ctx = CompareReportContext(
    left_name='left.svg',
    right_name='right.svg',
    mode=data['mode'],
    json_payload=data['json'],
    png_data_base64=data.get('png_data_base64'),
)

html = build_compare_report_html(ctx)

with open('report.html', 'w') as f:
    f.write(html)
"
```

---

## 8. Troubleshooting

### Issue: "Could not connect to http://localhost:8000"
**Solution:**
- Start the CompareLab server: `uvicorn app.main:app --reload`
- Check server is running: `curl http://localhost:8000/health`
- Use `--base-url` to specify different port

### Issue: "HTTP Error 404"
**Solution:**
- Verify `/compare/run` endpoint exists (B22.13 implementation)
- Check server logs for routing errors
- Confirm branch has B22.13 automation API merged

### Issue: No PNG preview in report
**Solution:**
- Server may not support PNG export yet
- Report is still valid, just shows "No PNG preview" message
- Implement PNG export in `/compare/run` response

### Issue: Layer table shows "No layer metadata"
**Solution:**
- Set `include_layers: true` in API request (already default in CLI)
- Verify compare engine returns `layers` array
- Check server logs for layer extraction errors

### Issue: Output file permission denied
**Solution:**
- Check output directory exists and is writable
- Use absolute path for `--out` parameter
- Run with appropriate permissions

---

## 9. Future Extensions (Nice to Have)

The report system is intentionally simple and extensible. Natural next steps:

### PDF Export
Wrap HTML via existing PDF generation stack:
```python
# Using weasyprint or similar
from weasyprint import HTML

def html_to_pdf(html_path: str, pdf_path: str):
    HTML(html_path).write_pdf(pdf_path)
```

### Batch Compare
Process entire directories:
```bash
# Conceptual CLI
python tools/compare_batch.py \
  --left-dir designs/v1/ \
  --right-dir designs/v2/ \
  --out-dir reports/batch/
```

### CI Golden Check
Fail build if diff changes unexpectedly:
```yaml
# .github/workflows/golden-diff.yml
- name: Check golden diffs
  run: |
    python tools/compare_report_cli.py \
      --left examples/golden/body.svg \
      --right tests/fixtures/current_body.svg \
      --out reports/ci_check.html
    
    # Assert no unexpected diffs (custom script)
    python tools/validate_golden_diff.py reports/ci_check.html
```

### Email/Slack Integration
Automatic report distribution:
```python
# Send report via email after generation
import smtplib
from email.mime.text import MIMEText

def email_report(html_path: str, recipient: str):
    with open(html_path) as f:
        msg = MIMEText(f.read(), "html")
    msg["Subject"] = "CompareLab Diff Report"
    msg["To"] = recipient
    # ... send via SMTP
```

---

## 10. Integration Checklist

- [x] Create `tools/compare_report_lib.py` with HTML builder
- [x] Create `tools/compare_report_cli.py` with API client
- [x] Create `docs/COMPARELAB_REPORTS.md` documentation
- [ ] Add example SVG pairs in `examples/comparelab/`
- [ ] Generate golden report for visual verification
- [ ] Create automated test for report generation
- [ ] Document in main README.md under "Compare Tools"
- [ ] Optional: Add PDF export wrapper
- [ ] Optional: Create batch compare script
- [ ] Optional: Add CI golden diff check

---

## 11. Related Documentation

- **B22.13 Automation API**: See `docs/B22_13_COMPARE_AUTOMATION_API.md`
- **B22.10 Compare Modes**: See `docs/B22_10_COMPARE_MODES.md`
- **B22.11 Layer-Aware Compare**: See `docs/B22_11_LAYER_AWARE_COMPARE.md`
- **B22.12 UI Export**: See `docs/B22_12_EXPORTABLE_DIFF_REPORTS.md`

---

## 12. Integration with Golden Checks & CI

**B22.16 Enhancement**: When the **golden compare CLI** runs in `check` or `check-all` mode
(`tools/compare_golden_cli.py`), it automatically generates HTML reports for each run.

### Automatic Report Generation

For each golden pair checked, the CLI:
1. Calls `/compare/run` with `export=["json","png"]`
2. Builds an HTML report using the same template as the manual report CLI
3. Writes to `reports/` directory (configurable via `--report-dir`)

**Filename pattern:**
```
reports/<left_stem>__vs__<right_stem>__PASS.html
reports/<left_stem>__vs__<right_stem>__DRIFT.html
```

### Example

```bash
# Check golden baseline
python tools/compare_golden_cli.py check \
  --baseline .golden/body_v1_vs_v2.json \
  --left body_v1.svg \
  --right body_v2.svg

# Output:
# ‚úÖ [PASS] body_v1_vs_v2.json
#    Report: reports/body_v1__vs__body_v2__PASS.html
```

### CI Workflow Integration

The CompareLab Golden Checks workflow (`.github/workflows/comparelab-golden.yml`):

1. **Runs golden checks:**
   ```bash
   python tools/compare_golden_cli.py check-all --dir .golden --report-dir reports
   ```

2. **Uploads all reports** (even on failure):
   ```yaml
   - name: Upload CompareLab reports
     if: always()
     uses: actions/upload-artifact@v4
     with:
       name: comparelab-reports
       path: reports/*.html
   ```

3. **Makes reports available** in GitHub Actions artifacts

### Accessing Reports in CI

When a golden check **fails** (drift detected):

1. **Open the workflow run** in GitHub Actions
2. **Download the `comparelab-reports` artifact**
3. **Open the corresponding `__DRIFT.html` file** in your browser

You'll see:
- Full visual comparison with PNG preview
- Bounding box changes
- Layer presence differences
- Detailed drift description

**This provides immediate visual feedback** on exactly how the geometry/layers changed between the golden baseline and current output.

### Benefits

- ‚úÖ **Automatic documentation** - Every golden check produces a visual report
- ‚úÖ **Drift diagnosis** - See exactly what changed without running locally
- ‚úÖ **Historical record** - Reports saved as CI artifacts (30 days default)
- ‚úÖ **Team collaboration** - Share reports with team members via artifact links
- ‚úÖ **No extra work** - Reports generated automatically during checks

### Local Development

```bash
# Check all golden baselines and generate reports
python tools/compare_golden_cli.py check-all --dir .golden

# Open reports in browser
open reports/*.html   # macOS
start reports/*.html  # Windows
xdg-open reports/*.html  # Linux
```

---

**Status:** ‚úÖ B22.14 Complete, B22.16 Integration Active  
**Next:** Stability Lap (docs sync + golden examples + sanity tests)
